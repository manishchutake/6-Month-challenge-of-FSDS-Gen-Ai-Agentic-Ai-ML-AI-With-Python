{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fd9a530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install  -q  -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc561262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GEMINI_API_KEY'] =" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad717c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ai-future/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/var/folders/w8/5124_l8n1md8s19brt04j5mr0000gn/T/ipykernel_4679/1295831231.py:1: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  import google.generativeai as genai\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "genai.configure(api_key = os.environ['GEMINI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27bbd825",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('models/gemini-2.5-flash-preview-09-2025')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b084a5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table below outlines the key differences between Artificial Intelligence (AI), Machine Learning (ML), Generative AI, and Large Language Models (LLMs).\n",
      "\n",
      "| Feature / Category | Artificial Intelligence (AI) | Machine Learning (ML) | Generative AI | Large Language Model (LLM) |\n",
      "|---|---|---|---|---|\n",
      "| **Scope / Definition** | The broad field of creating systems that mimic human intelligence. | A subset of AI where systems learn from data *without* being explicitly programmed. | A subset of ML focused on creating **new content** (text, images, audio, code). | A specific type of Generative AI, trained on massive text datasets, specialized in language tasks. |\n",
      "| **Hierarchy (Relationship)** | **Superset** (All others fall under AI) | A **subset** of AI | A **subset** of ML (and therefore AI) | A **type/instance** of Generative AI |\n",
      "| **Core Goal / Function** | To enable machines to solve problems and make decisions intelligently. | To build models that can analyze data, learn patterns, and make predictions or classifications. | To **generate novel outputs** that resemble the data they were trained on (creation). | To understand, generate, summarize, translate, and answer questions in human-like language. |\n",
      "| **Input Type** | Varies (data, rules, logic) | Data (labeled or unlabeled) | Data (text, images, code, etc.) | Massive amounts of text and code data. |\n",
      "| **Output Type** | Decisions, actions, solutions. | Predictions, classifications, clustering. | New, unique content (images, stories, music, code). | Coherent, contextual human language (responses, essays, summaries). |\n",
      "| **Key Techniques** | Search algorithms, logic programming, expert systems, neural networks. | Supervised learning, Unsupervised learning, Reinforcement learning. | Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), Transformers. | Transformer architecture (specifically the \"decoder-only\" stack). |\n",
      "| **Examples** | Self-driving cars (overall system), Siri/Alexa (initial implementation), Expert systems. | Spam filters, Recommendation engines, Predictive stock analysis. | DALL-E, Midjourney (image generation), ChatGPT (text), Music generation tools. | GPT-4, Llama, PaLM 2, Claude, Bard/Gemini. |\n",
      "| **Time Frame** | Began in the 1950s. | Gained prominence in the 1980s/1990s. | Became widely popular around 2017-2022. | Dominant since 2018 (with the rise of the Transformer architecture). |\n"
     ]
    }
   ],
   "source": [
    "response = model.generate_content(\"tabular format of the answer difference between ai vs ml vs gen ai vs LLM\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e61b8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "import google.generativeai as genai\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "def to_markdown(text):\n",
    "    text = text.replace('.', '*')\n",
    "    return Markdown(textwrap.indent(text, '>', predicate=lambda _: True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "403d003d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-2.5-flash\n",
      "models/gemini-2.5-pro\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/gemma-3n-e4b-it\n",
      "models/gemma-3n-e2b-it\n",
      "models/gemini-flash-latest\n",
      "models/gemini-flash-lite-latest\n",
      "models/gemini-pro-latest\n",
      "models/gemini-2.5-flash-lite\n",
      "models/gemini-2.5-flash-image-preview\n",
      "models/gemini-2.5-flash-image\n",
      "models/gemini-2.5-flash-preview-09-2025\n",
      "models/gemini-2.5-flash-lite-preview-09-2025\n",
      "models/gemini-3-pro-preview\n",
      "models/gemini-3-flash-preview\n",
      "models/gemini-3-pro-image-preview\n",
      "models/nano-banana-pro-preview\n",
      "models/gemini-robotics-er-1.5-preview\n",
      "models/gemini-2.5-computer-use-preview-10-2025\n",
      "models/deep-research-pro-preview-12-2025\n"
     ]
    }
   ],
   "source": [
    "for m  in genai.list_models():\n",
    "    if 'generateContent' in m.supported_generation_methods:\n",
    "        print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb53949",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('models/gemini-2.5-flash-preview-09-2025')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7caa5e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       ">## Data Science vs* Machine Learning: A Kid-Friendly Look! ðŸš€\n",
       ">\n",
       ">| Feature | Data Science (The **Detective** ðŸ•µï¸â€â™€ï¸) | Machine Learning (The **Smart Robot** ðŸ¤–) |\n",
       ">| :--- | :--- | :--- |\n",
       ">| **What is it?** | Finding *stories* and *secrets* hidden in big piles of numbers (data)* | Teaching a computer to *learn* from examples, without being told every single step! |\n",
       ">| **Main Goal** | To **understand** the world and answer big questions (like \"Why did the toy truck break?\") | To **predict** the future or make smart decisions (like \"Will this toy truck break soon?\") |\n",
       ">| **Tools Used** | Math, charts, graphs, and asking lots of \"Why?\" questions* | Special recipes (called *algorithms*) that help the computer practice and learn* |\n",
       ">| **Example Question** | \"What kind of ice cream do kids in this town like the *most*?\" | \"If I show the computer pictures of cats and dogs, can it tell me which is which?\" |\n",
       ">| **How long does it take?** | Takes time to explore, clean up the data, and make beautiful charts* | Once the computer is trained, it can make decisions *very* quickly! |\n",
       ">| **The Outcome** | **Insights** (clever observations) and helpful **reports** for people to read* | A **model** (the brain) that can make automatic **predictions** or choices* |\n",
       ">| **Best Analogy** | **The Chef:** Decides what ingredients (data) to use and how to prepare the meal (analysis)* | **The Ovens/Mixer:** The tools that help turn the ingredients into a finished dish (the prediction)* |\n",
       ">| **Do they work together?** | **YES!** Data Science cleans up the data and sets the stage, and then Machine Learning uses that clean data to build the Smart Robot! | |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.generate_content('create a table for  summarizeto a kid about datascience vs machine learning')\n",
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcceb3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1bdbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4559000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-future",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
