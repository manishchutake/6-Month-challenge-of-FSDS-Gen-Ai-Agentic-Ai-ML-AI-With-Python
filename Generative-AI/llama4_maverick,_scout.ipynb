{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DaYbm6R29sG",
        "outputId": "e231804a-c415-4fe2-a165-a034918ca23c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "While it's challenging to predict the future with certainty, I can provide some insights based on current trends and forecasts. Here's an analysis of the AI job market in 2026:\n",
            "\n",
            "**Growing demand for AI professionals**\n",
            "\n",
            "The demand for AI professionals is expected to continue growing in the coming years. According to a report by Indeed, the number of AI job postings has increased by 119% over the past year. Another report by Glassdoor predicts that the demand for AI professionals will grow by 34% annually from 2020 to 2026.\n",
            "\n",
            "**Top AI job roles in 2026**\n",
            "\n",
            "Some of the top AI job roles that are expected to be in high demand in 2026 include:\n",
            "\n",
            "1. **AI/ML Engineer**: Design, develop, and deploy AI and ML models and systems.\n",
            "2. **Data Scientist**: Analyze and interpret complex data to inform business decisions and develop AI/ML models.\n",
            "3. **AI Research Scientist**: Conduct research and development in AI and ML to improve existing algorithms and develop new ones.\n",
            "4. **AI/ML Operations Engineer**: Deploy, manage, and maintain AI/ML models and systems in production environments.\n",
            "5. **Conversational AI Designer**: Design and develop conversational interfaces, such as chatbots and voice assistants.\n",
            "6. **Computer Vision Engineer**: Develop and deploy computer vision algorithms and systems for applications such as image recognition and object detection.\n",
            "7. **Natural Language Processing (NLP) Engineer**: Develop and deploy NLP algorithms and systems for applications such as text analysis and language translation.\n",
            "8. **AI Ethics and Bias Specialist**: Ensure that AI systems are fair, transparent, and unbiased.\n",
            "9. **AI Business Development Manager**: Identify and develop business opportunities related to AI and ML.\n",
            "10. **AI Product Manager**: Oversee the development and launch of AI-powered products.\n",
            "\n",
            "**Skills required for AI jobs in 2026**\n",
            "\n",
            "To be successful in AI jobs in 2026, professionals will need to possess a range of skills, including:\n",
            "\n",
            "1. **Programming skills**: Proficiency in languages such as Python, Java, and C++.\n",
            "2. **AI and ML frameworks**: Knowledge of frameworks such as TensorFlow, PyTorch, and Keras.\n",
            "3. **Data analysis and science**: Skills in data analysis, visualization, and interpretation.\n",
            "4. **Cloud computing**: Experience with cloud platforms such as AWS, Azure, and Google Cloud.\n",
            "5. **Communication and collaboration**: Ability to communicate complex ideas to non-technical stakeholders and work collaboratively with cross-functional teams.\n",
            "6. **Domain expertise**: Knowledge of specific industries or domains, such as healthcare, finance, or transportation.\n",
            "7. **Ethics and bias**: Understanding of AI ethics and bias, and ability to develop fair and transparent AI systems.\n",
            "\n",
            "**Emerging trends in AI jobs**\n",
            "\n",
            "Some emerging trends that are expected to shape the AI job market in 2026 include:\n",
            "\n",
            "1. **Increased focus on explainability and transparency**: As AI becomes more pervasive, there will be a growing need for professionals who can explain and interpret AI decisions.\n",
            "2. **Growing demand for edge AI**: With the proliferation of IoT devices, there will be a growing need for AI professionals who can develop and deploy AI models on edge devices.\n",
            "3. **More emphasis on human-AI collaboration**: As AI becomes more integrated into workplaces, there will be a growing need for professionals who can design and develop systems that facilitate human-AI collaboration.\n",
            "\n",
            "While it's difficult to predict the future with certainty, these trends and forecasts suggest that the demand for AI professionals will continue to grow in the coming years, with a focus on developing skills in areas such as AI/ML engineering, data science, and AI ethics and bias."
          ]
        }
      ],
      "source": [
        "import os\n",
        "from groq import Groq\n",
        "\n",
        "# Replace 'YOUR_GROQ_API_KEY' with your actual Groq API key\n",
        "os.environ[\"GROQ_API_KEY\"] = \"\"\n",
        "\n",
        "client = Groq()\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"meta-llama/llama-4-maverick-17b-128e-instruct\",\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"about ai job opening in 2026 \"\n",
        "      }\n",
        "    ],\n",
        "    temperature=0.7,\n",
        "    max_completion_tokens=1024,\n",
        "    top_p=1,\n",
        "    stream=True,\n",
        "    stop=None\n",
        ")\n",
        "\n",
        "for chunk in completion:\n",
        "    print(chunk.choices[0].delta.content or \"\", end=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAvWgFsf3ro_",
        "outputId": "9fa531e7-9e76-4165-84ae-d1c5e297442d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-1.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
            "Downloading groq-1.0.0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install groq\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaSXwKqV5CTH",
        "outputId": "2b47e1ed-b98b-467c-c429-34e85ff563c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What a beautiful and imaginative request!\n",
            "\n",
            "Unfortunately, I'm a text-based AI and do not have the capability to generate images directly. However, I can try to help you with a descriptive passage of a horse riding in the moonlight, or provide you with some suggestions on how to find or create such an image.\n",
            "\n",
            "If you'd like, I can describe a serene and magical scene:\n",
            "\n",
            "\"In the stillness of the night, a majestic horse with a shiny coat and a flowing mane gallops effortlessly across the lunar surface. The moon's soft, silvery light illuminates the horse's path, casting an ethereal glow on the surrounding craters and rocks. The horse's hooves barely touch the ground, as if it's floating on the moon's low gravity. The stars twinkle like diamonds in the dark sky, and the Earth, a blue-green marble, hangs low on the horizon. The horse's rider, dressed in a flowing white cloak, sits confidently astride, their face upturned to the stars. Together, they ride across the moon's surface, leaving behind a trail of glittering stardust.\"\n",
            "\n",
            "If you'd like to find or create an image like this, you can try:\n",
            "\n",
            "1. **Stock photo websites**: Search for keywords like \"horse riding moon\", \"lunar horse\", \"moonlit horse\", or \"space horse\" on stock photo websites like Unsplash, Pexels, or Getty Images.\n",
            "2. **Digital art platforms**: Visit platforms like DeviantArt, ArtStation, or Behance, where artists often share their digital art creations, including illustrations and concept art.\n",
            "3. **Commission an artist**: If you have a specific idea in mind, consider commissioning a digital artist to create a custom image for you.\n",
            "4. **Generate with AI**: There are AI-powered tools like DALL-E, Midjourney, or Deep Dream Generator that can generate images based on text prompts. Keep in mind that these tools are still experimental and may not always produce the desired results.\n",
            "\n",
            "Let me know if there's anything else I can help you with!"
          ]
        }
      ],
      "source": [
        "from groq import Groq\n",
        "\n",
        "client = Groq()\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"can you generate horse image riding in moon\"\n",
        "      }\n",
        "    ],\n",
        "    temperature=0.7,\n",
        "    max_completion_tokens=1024,\n",
        "    top_p=1,\n",
        "    stream=True,\n",
        "    stop=None\n",
        ")\n",
        "\n",
        "for chunk in completion:\n",
        "    print(chunk.choices[0].delta.content or \"\", end=\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWPxwZwR5wL6",
        "outputId": "24b33ef1-0715-48d6-c6b7-f515793b5dcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is a compact, self‑contained primer that compares **MCP** (the most common meanings you’ll encounter in AI circles) with **agentic AI**. I’ve tried to cover the major variants of “MCP” that people usually mean, point out where the terminology overlaps, and then lay out a side‑by‑side comparison of the two paradigms. If you had a different MCP in mind, just let me know and I can tailor the answer further!  \n",
            "\n",
            "---\n",
            "\n",
            "## 1️⃣ What “MCP” Usually Refers To\n",
            "\n",
            "| Acronym | Full name | Core idea | Typical use‑cases | Key papers / resources |\n",
            "|---------|-----------|-----------|-------------------|------------------------|\n",
            "| **MCP** | **Model‑Conditioned Prompting** (also called *Model‑Conditional Prompting* or *Model‑Conditioned Programming*) | You treat a large language model (LLM) as a **pure function** that you can *condition* on external variables, state, or tools. The prompt explicitly tells the model *“given this context, produce X”* and the surrounding code handles the conditioning logic. | Structured text generation, data extraction, “few‑shot” pipelines where the model must obey a strict contract (e.g., “output JSON only”). | “Prompt Programming for LLMs” (Wei et al., 2022); “Program‑Synthesis with LLMs” (Chen et al., 2023). |\n",
            "| **MCP** | **Model‑Centric Programming** (a.k.a. *LLM‑Centric Development*) | The **entire program** is expressed as a series of LLM calls, with the developer writing *meta‑prompts* that orchestrate the flow. The model does the heavy lifting (reasoning, planning, code generation). | Rapid prototyping of agents, “no‑code” AI workflows, internal‑tool building. | “LLM‑Centric Programming” (OpenAI blog, 2023); “ReAct: Synergizing Reasoning and Acting in Language Models” (Yao et al., 2022). |\n",
            "| **MCP** | **Model‑Checking & Planning** (in formal methods) | Treat the LLM as a *system* whose possible outputs can be exhaustively explored via model‑checking techniques to guarantee safety properties. | Safety‑critical LLM deployments, verification of policy compliance. | “Verifying LLMs with Model‑Checking” (Kumar et al., 2024). |\n",
            "| **MCP** | **Multi‑Component Prompting** (rare) | A prompt is split into *modules* (knowledge, reasoning, constraints) that the model processes sequentially. | Complex reasoning chains, chain‑of‑thought style prompts. | “Modular Prompt Design” (Sanh et al., 2022). |\n",
            "\n",
            "> **TL;DR:** In most AI‑product and research discussions today, “MCP” ≈ *a disciplined way of writing prompts and surrounding code so that the LLM behaves like a deterministic sub‑routine*. It is **prompt‑centric** rather than **agent‑centric**.\n",
            "\n",
            "---\n",
            "\n",
            "## 2️⃣ What “Agentic AI” Means\n",
            "\n",
            "| Term | Short definition | Core components | Typical archetype |\n",
            "|------|------------------|----------------|-------------------|\n",
            "| **Agentic AI** | An AI system that **acts autonomously** toward a goal, *perceives* its environment, *plans*, and *executes* actions (including tool use, web calls, or physical actuation). | 1. **Goal/Utility** (explicit or learned) 2. **Perception** (input from world) 3. **Planning/Reasoning** (often via LLM chain‑of‑thought) 4. **Actuation** (API calls, UI interactions) 5. **Memory/State** (short‑term or long‑term) | ChatGPT with browsing + function calling, AutoGPT, BabyAGI, ReAct agents, LangChain‑based bots. |\n",
            "\n",
            "Key ideas that set agentic AI apart:\n",
            "\n",
            "* **Closed‑loop**: The system observes the result of its own actions and updates its plan.\n",
            "* **Self‑directed**: The agent decides *what* to do next (e.g., “search the web”, “summarize”, “ask the user”) rather than just answering a single prompt.\n",
            "* **Tool use**: Integration with external APIs (search, database, code execution) is a first‑class capability.\n",
            "* **Persistence**: Memory modules (vector stores, relational DBs) let the agent retain information across sessions.\n",
            "\n",
            "---\n",
            "\n",
            "## 3️⃣ Head‑to‑Head: MCP vs. Agentic AI\n",
            "\n",
            "| Dimension | MCP (Prompt‑Centric) | Agentic AI (Autonomous Agent) |\n",
            "|-----------|----------------------|------------------------------|\n",
            "| **Control Flow** | *Top‑down*: The developer writes the control flow (if‑else, loops) and inserts LLM calls as pure functions. | *Bottom‑up*: The LLM (or a small policy network) decides the next action; the loop is inside the agent. |\n",
            "| **State Management** | Usually **stateless** per call; any state is passed explicitly in the prompt (e.g., “Here is the conversation so far”). | **Explicit memory** (vector DB, key‑value store) + internal state that persists across calls. |\n",
            "| **Predictability** | High – the prompt + deterministic sampling (e.g., temperature = 0) yields reproducible output. | Lower – the agent’s internal planning can produce divergent action sequences. |\n",
            "| **Tool Integration** | Hand‑crafted: the surrounding code decides *when* to call a tool, then feeds the result back as part of the next prompt. | Native: the agent can *decide* to call a tool, parse the tool’s response, and continue reasoning automatically (e.g., ReAct). |\n",
            "| **Typical Applications** | • Data transformation pipelines <br>• Structured generation (JSON, SQL) <br>• “Prompt‑as‑code” prototypes | • Personal assistants <br>• Autonomous research bots <br>• Automated troubleshooting <br>• Game‑playing agents |\n",
            "| **Safety / Verification** | Easier to audit because the *only* decision point is the prompt; you can run static analysis on the surrounding code. | Harder: you need runtime monitoring, sandboxing, and possibly formal verification (MCP‑style model checking can be applied as a safety overlay). |\n",
            "| **Scalability** | Scales linearly with the number of prompt calls; each call is independent. | Can scale recursively (agents spawn sub‑agents) but may incur exponential cost if not throttled. |\n",
            "| **Development Speed** | Very fast for “one‑off” tasks; you just write a prompt and a thin wrapper. | Slower to get right because you have to design goal formulation, memory schema, tool contracts, and fallback strategies. |\n",
            "| **Failure Modes** | *Prompt drift*: ambiguous wording leads to malformed output. | *Goal drift*: the agent pursues a sub‑optimal or unsafe plan; tool misuse; infinite loops. |\n",
            "\n",
            "### Where the Two Overlap\n",
            "\n",
            "| Scenario | How MCP Helps Agentic AI | How Agentic AI Enhances MCP |\n",
            "|----------|--------------------------|-----------------------------|\n",
            "| **Complex Tool Chaining** | Use MCP to *wrap* each tool call in a deterministic prompt (“given the JSON result, produce a valid SQL query”). | The agent decides *which* tool to call next, so you get dynamic pipelines instead of a static chain. |\n",
            "| **Safety Guardrails** | Apply **Model‑Checking & Planning** (MCP) as a verification layer that simulates the agent’s next few steps and aborts unsafe actions. | The agent can request a *verification* step as part of its plan, making safety a first‑class action. |\n",
            "| **Memory Retrieval** | Prompt‑condition the LLM with retrieved passages (MCP style) to keep the model grounded. | The agent decides *what* memory to fetch, using relevance scores or curiosity‑driven queries. |\n",
            "\n",
            "---\n",
            "\n",
            "## 4️⃣ Practical Guide: When to Pick Which\n",
            "\n",
            "| Situation | Recommended Paradigm | Quick “starter” stack |\n",
            "|-----------|----------------------|------------------------|\n",
            "| **You need a single, well‑defined transformation (e.g., turn emails → tickets).** | MCP – write a robust prompt, set temperature = 0, add schema validation. | `openai.ChatCompletion → python function → pydantic schema` |\n",
            "| **You are building a chatbot that must browse, schedule, and follow‑up.** | Agentic AI – give the bot a goal, let it decide when to browse or call calendar APIs. | LangChain + ReAct + `toolkits` (search, calendar, python REPL) |\n",
            "| **Safety‑critical compliance (e.g., legal document drafting).** | Combine both: MCP for the deterministic drafting step, Agentic AI for the “research” phase, with a model‑checking guard. | `LLM‑Centric Program → Model‑Check → Agent Loop` |\n",
            "| **Rapid prototyping of a new workflow** | Start with MCP (fast), then evolve to an agent if you notice the workflow needs dynamic branching. | Jupyter notebook → prompt‑templates → later wrap in LangChain agent. |\n",
            "| **Long‑running autonomous research (e.g., literature review over weeks).** | Agentic AI with persistent memory; optionally embed MCP‑style prompts for each literature‑extraction step. | AutoGPT / BabyAGI + vector store + Retrieval‑augmented generation (RAG). |\n",
            "\n",
            "---\n",
            "\n",
            "## 5️⃣ Sample Code Sketches\n",
            "\n",
            "### 5.1 MCP‑Style Prompt Wrapper (Python)\n",
            "\n",
            "```python\n",
            "import openai\n",
            "from pydantic import BaseModel, ValidationError\n",
            "\n",
            "class Ticket(BaseModel):\n",
            "    title: str\n",
            "    description: str\n",
            "    priority: str\n",
            "\n",
            "def email_to_ticket(email_body: str) -> Ticket:\n",
            "    # 1️⃣ Condition the model on the input email\n",
            "    prompt = f\"\"\"You are a help‑desk assistant. Convert the following email into a JSON ticket that matches this schema:\n",
            "{Ticket.schema_json(indent=2)}\n",
            "\n",
            "Email:\n",
            "\\\"\\\"\\\"\n",
            "{email_body}\n",
            "\\\"\\\"\\\"\n",
            "\n",
            "Respond with ONLY the JSON object.\"\"\"\n",
            "    response = openai.ChatCompletion.create(\n",
            "        model=\"gpt-4o-mini\",\n",
            "        messages=[{\"role\":\"user\",\"content\":prompt}],\n",
            "        temperature=0,  # deterministic\n",
            "    )\n",
            "    raw = response.choices[0].message.content.strip()\n",
            "    # 2️⃣ Validate the JSON against the schema\n",
            "    try:\n",
            "        return Ticket.parse_raw(raw)\n",
            "    except ValidationError as e:\n",
            "        raise ValueError(f\"Invalid ticket format: {e}\")\n",
            "\n",
            "# Usage\n",
            "ticket = email_to_ticket(\"Hi, the server is down and we need it fixed ASAP!\")\n",
            "print(ticket)\n",
            "```\n",
            "\n",
            "*Key MCP traits*: explicit conditioning, deterministic sampling, schema validation outside the model.\n",
            "\n",
            "### 5.2 Minimal Agentic AI (ReAct style) with LangChain\n",
            "\n",
            "```python\n",
            "from langchain.agents import initialize_agent, Tool\n",
            "from langchain.llms import OpenAI\n",
            "from langchain.utilities import GoogleSerperAPIWrapper\n",
            "\n",
            "# 1️⃣ Define tools the agent may call\n",
            "search = Tool(\n",
            "    name=\"WebSearch\",\n",
            "    func=GoogleSerperAPIWrapper().run,\n",
            "    description=\"Search the web for up‑to‑date information.\"\n",
            ")\n",
            "\n",
            "def write_summary(query: str) -> str:\n",
            "    # This is a *sub‑agent* that uses MCP internally\n",
            "    return email_to_ticket(f\"Summarize findings for: {query}\")\n",
            "\n",
            "summarize = Tool(\n",
            "    name=\"Summarize\",\n",
            "    func=write_summary,\n",
            "    description=\"Given a short query, produce a concise summary as a ticket.\"\n",
            ")\n",
            "\n",
            "# 2️⃣ Build the ReAct agent\n",
            "llm = OpenAI(model=\"gpt-4o\")\n",
            "agent = initialize_agent(\n",
            "    tools=[search, summarize],\n",
            "    llm=llm,\n",
            "    agent_type=\"react-docstore\",\n",
            "    verbose=True,\n",
            ")\n",
            "\n",
            "# 3️⃣ Run the agent with a high‑level goal\n",
            "goal = \"Investigate why the login page is returning 500 errors and create a ticket for the dev team.\"\n",
            "agent.run(goal)\n",
            "```\n",
            "\n",
            "*What’s happening*:\n",
            "\n",
            "* The **agent** decides whether to call `WebSearch` or `Summarize`.\n",
            "* The `Summarize` tool internally **uses MCP** (`email_to_ticket`) to guarantee the output format.\n",
            "* The loop (`ReAct`) gives the system a closed feedback cycle—classic agentic behavior.\n",
            "\n",
            "---\n",
            "\n",
            "## 6️⃣ Emerging Research Threads\n",
            "\n",
            "| Trend | How it Bridges MCP & Agentic AI |\n",
            "|-------|---------------------------------|\n",
            "| **Tool‑aware prompting** (e.g., “function‑calling” in OpenAI’s API) | Prompt templates (MCP) embed a *function schema* that the model can invoke automatically—blurring the line between a static prompt and an autonomous decision. |\n",
            "| **Self‑Verification** (e.g., “self‑critiquing” LLMs) | Agents ask the model to *check* its own output against a schema (MCP‑style validation) before committing an action. |\n",
            "| **Neuro‑symbolic agents** | Symbolic planners generate a high‑level plan; LLMs fill in the details via MCP prompts. |\n",
            "| **Formal verification for agents** | Researchers are using **model‑checking** (the MCP‑formal‑methods sense) to prove that an agent’s policy never triggers a forbidden tool call. |\n",
            "| **Meta‑learning of prompts** | Agents learn to *generate better prompts* for downstream MCP calls, effectively “learning to program themselves”. |\n",
            "\n",
            "---\n",
            "\n",
            "## 7️⃣ Quick‑Start Checklist\n",
            "\n",
            "| Goal | Choose MCP if… | Choose Agentic AI if… |\n",
            "|------|----------------|-----------------------|\n",
            "| **Deterministic output format** | ✅ Yes – you can enforce a schema via prompting. | ❌ May need extra validation. |\n",
            "| **Single‑step transformation** | ✅ Yes – one LLM call does the job. | ❌ Overkill. |\n",
            "| **Dynamic branching, tool selection, or looping** | ❌ You’d have to hand‑code all branches. | ✅ Agents decide the next step. |\n",
            "| **Long‑term memory across sessions** | ❌ Requires manual stitching of prompts. | ✅ Built‑in memory modules. |\n",
            "| **Safety guarantees (regulatory compliance)** | ✅ Easy to add schema checks, static analysis. | ✅ Add model‑checking layer, but more work. |\n",
            "| **Rapid prototyping** | ✅ Write a prompt + a few lines of Python. | ❌ Needs agent scaffolding. |\n",
            "\n",
            "---\n",
            "\n",
            "## 8️⃣ TL;DR Summary\n",
            "\n",
            "* **MCP** = **prompt‑centric programming**. You write a deterministic prompt, optionally wrap it with code that passes in external state and validates the output. Great for *single‑purpose, well‑defined transformations*.\n",
            "* **Agentic AI** = **autonomous decision‑making systems** that perceive, plan, act, and remember. Ideal when the workflow is *open‑ended, requires tool selection, or runs over many steps*.\n",
            "* The two are **complementary**: an agent often **calls** MCP‑styled functions to guarantee format, while MCP pipelines can be **augmented** with a lightweight agent to decide *when* to invoke each step.\n",
            "* In practice, most production systems today are **hybrids**—a small “controller” agent orchestrates a library of MCP‑validated tool calls.\n",
            "\n",
            "---\n",
            "\n",
            "### Next Steps for You\n",
            "\n",
            "1. **Identify the granularity of your task.** If you can describe the whole job in a single prompt + schema, start with MCP.\n",
            "2. **Prototype the MCP component first** (the code block in §5.1). Verify that the model respects the schema 100 % of the time (run a few hundred samples).\n",
            "3. **Wrap the MCP function inside an agent** (the skeleton in §5.2) only if you discover that the workflow needs *conditional branching* or *external tool use*.\n",
            "4. **Add a verification layer** (e.g., a lightweight model‑checker that simulates the next 2‑3 actions) if safety/compliance is a concern.\n",
            "5. **Iterate**: as the agent’s behavior grows, you’ll likely add more MCP‑style “sub‑routines” to keep the system interpretable and auditable.\n",
            "\n",
            "---\n",
            "\n",
            "**Hope this clears the landscape!** If you want deeper dives—e.g., a walkthrough of formal model‑checking for agent policies, or a full code repo that mixes LangChain agents with Pydantic‑validated MCP calls—just let me know. Happy building!"
          ]
        }
      ],
      "source": [
        "from groq import Groq\n",
        "\n",
        "client = Groq()\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"openai/gpt-oss-120b\",\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"about mcp vs agentic ai \"\n",
        "      }\n",
        "    ],\n",
        "    temperature=1,\n",
        "    max_completion_tokens=8192,\n",
        "    top_p=1,\n",
        "    reasoning_effort=\"medium\",\n",
        "    stream=True,\n",
        "    stop=None\n",
        ")\n",
        "\n",
        "for chunk in completion:\n",
        "    print(chunk.choices[0].delta.content or \"\", end=\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31300Y3z6N8y",
        "outputId": "b98a6a6f-8b1e-40c3-d6bf-ededa8082a22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comparison snapshot: All four concepts are complementary layers in a modern AI stack, not mutually exclusive generations.\n",
            "\n",
            "| Dimension | Traditional AI (Predictive/Analytical) | Generative AI (Gen-AI) | Agentic AI (Goal-driven autonomous agents) | MCP (Model-Context-Protocol / “Model-Connect-Platform”) |\n",
            "|-----------|-------------------------------------------|------------------------|--------------------------------------------|----------------------------------------------------------|\n",
            "| Primary purpose | Predict, classify, optimize | Create new content (text, code, image, audio, video) | Take sequences of actions to reach a goal | Standardize how any AI (or data source) is invoked, secured, observed and paid for |\n",
            "| Core capability | Pattern recognition & supervised learning | Probabilistic generation via LLMs, diffusion, etc. | Planning, memory, tool-use, feedback loops | Secure, versioned, metered API / SDK for models & data |\n",
            "| Typical output | Score, label, forecast | Novel artifact (document, image, code) | Completed task or multi-step workflow | Callable endpoint that hides vendor & infra details |\n",
            "| Decision loop | Human-in-the-loop | Human-in-the-loop (mostly) | Closed-loop autonomy with human oversight | Not a decision maker; supplies context & tools to decision makers |\n",
            "| Data needed | Labelled training set | Large unlabelled corpora | Real-time environment feedback + knowledge base | Metadata, credentials, rate-limits, audit logs |\n",
            "| Compute profile | Training: medium; Inference: low–medium | Training: very high; Inference: high | Iterative prompt + tool calls → high token cost | Negligible overhead; acts as router |\n",
            "| Key metrics | Accuracy, precision-recall, F1 | Perplexity, BLEU, human rating, latency | Task success rate, steps-to-goal, cost-per-goal | Latency, TPS, authN/Z success, $/call |\n",
            "| Hallmarks / risks | Bias, drift, explainability | Hallucination, IP leakage, toxicity | Runaway loops, tool misuse, cost explosion | Vendor lock-in, governance gaps, hidden latency |\n",
            "| Human role | Label data, validate results | Prompt, refine, moderate | Set objective & guardrails, intervene if needed | Register models, set policies, monitor dashboards |\n",
            "| Tooling & infra | Scikit, XGBoost, MLflow, Vertex, SageMaker | Transformers, LangChain, HuggingFace, DALL·E | AutoGPT, CrewAI, LangGraph, BabyAGI, Microsoft Autogen | MCP server/client SDKs, API gateway, policy engine, metering service |\n",
            "| Maturity | Production-grade since ~2015 | Rapid adoption since 2022; governance catching up | Experimental → early prod (2024) | Specification phase (2024); reference impl. starting |\n",
            "| Example use-case | Fraud detection, demand forecast | Marketing copy, code assistant | “Book the cheapest eco-friendly flight, then cancel if price drops” | Same use-case, but MCP supplies airline & payment APIs with audit trail |\n",
            "| Interaction style | Batch or REST score | Prompt → response | Loop: perceive → plan → act → observe → repeat | Any AI or app calls `mcp.invoke(model_id, context, tools)` |\n",
            "| Extensibility | Add features, retrain | Fine-tune, RAG, prompt eng. | Plug in new tools, memory, planners | Swap models or data sources without client code change |\n",
            "| Governance focus | Model cards, drift tests | Content filters, licensing, PII scrubbing | Sandboxing, tool whitelists, spend caps | AuthN/Z, rate limits, audit, cost allocation, SLA |\n",
            "| Open-source posture | Mature OSS libs | Many OSS weights & datasets | Emerging frameworks, few standards | Protocol open-source; vendor implementations vary |\n",
            "| Cost driver | Data labelling, retraining | GPU hours, token volume | Iterative LLM calls + tool fees | API call volume; negligible vs. model cost |\n",
            "| Security surface | Model file, training data | Prompt injection, data exfiltration | Tool misuse, privilege escalation | Credential vault, policy engine, encrypted transport |\n",
            "| Human-in-the-loop point | Training & validation | Prompting & output review | Objective setting & emergency stop | Policy authoring & monitoring |\n",
            "| Lifecycle stage | Mature | Early mainstream | Nascent | Specification |\n",
            "| Combinability | Feeds features into Gen-AI | Can be wrapped by Agentic AI | Uses Gen-AI for reasoning; uses MCP for tools | Serves any of the above uniformly |\n",
            "\n",
            "How they fit together  \n",
            "Traditional AI → provides fast, cheap predictions (fraud score, churn propensity).  \n",
            "Gen-AI → drafts content or code informed by those predictions.  \n",
            "Agentic AI → orchestrates a campaign: use the churn score, generate personalized e-mails, send via CRM, monitor open-rate, iterate.  \n",
            "MCP → exposes the churn model, the Gen-AI endpoint, the CRM tool, and the analytics warehouse under one secure, metered interface so the agent (or any app) can call them without hard-coding vendor specifics."
          ]
        }
      ],
      "source": [
        "from groq import Groq\n",
        "\n",
        "client = Groq()\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"creat comparision table about ai vs genai vs agentic ai vs mcp \"\n",
        "      }\n",
        "    ],\n",
        "    temperature=0.6,\n",
        "    max_completion_tokens=4096,\n",
        "    top_p=1,\n",
        "    stream=True,\n",
        "    stop=None\n",
        ")\n",
        "\n",
        "for chunk in completion:\n",
        "    print(chunk.choices[0].delta.content or \"\", end=\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5hklnce6RAs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
