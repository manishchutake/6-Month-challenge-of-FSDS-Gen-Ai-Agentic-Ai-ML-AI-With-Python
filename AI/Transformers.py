# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x723fgh54p5Vl9rRLX8zJ9tP0eQGzyMK
"""

!nvidia-smi

!pip install transformers

from transformers import AutoTokenizer
# load the tokeizer for a specific model(e.g. GPT-2)
tokenizer = AutoTokenizer.from_pretrained("gpt2")

# Tokenize some input text
text = "Hello, how are you?"
tokens = tokenizer(text, return_tensors = 'pt')
print(tokens)

from transformers import AutoModelForCausalLM
# load the pretrained GPT-2 model
model = AutoModelForCausalLM.from_pretrained("gpt2")
# Generate texts
input_ids = tokenizer.encode("india economy", return_tensors ='pt')
output = model.generate(input_ids, max_length = 100)
generated_text = tokenizer.decode(output[0], skip_special_tokens = True)
print(generated_text)

# Hugging face model
from transformers import pipeline, set_seed
generator = pipeline('text-generation', model='gpt2')
set_seed(42)
generator("Hello, I'm a language model,", max_length=30, num_return_sequences=5)







